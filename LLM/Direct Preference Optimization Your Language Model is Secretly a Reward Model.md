# 【NIPS 2023】 Direct Preference Optimization: Your Language Model is Secretly a Reward Model

阅读时间：1030
斯坦福大学

## Motivation


## Idea
如何不借助奖励模型利用成对的正负样本进行偏好预测