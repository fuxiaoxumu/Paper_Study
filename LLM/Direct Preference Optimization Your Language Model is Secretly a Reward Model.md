# 【NIPS 2023】 Direct Preference Optimization: Your Language Model is Secretly a Reward Model

阅读时间：1125

## Motivation
语言模型策略和奖励函数之间的映射

## Idea
如何不借助奖励模型利用成对的正负样本进行偏好预测
几乎不调整超参数？